{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         # \"\"\"多機版---20190507\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "\n",
    "print('鋼網印刷品質監控中，請勿關閉程序！')\n",
    "\n",
    "def diff_data(data):\n",
    "    p=adfuller(data[u'NAME'],1)[1]\n",
    "    q=float(acorr_ljungbox(data,lags=1)[1])   \n",
    "    D_data=data.diff().dropna()\n",
    "    D_data.columns=[u'NAME']\n",
    "    D_data.dropna(inplace=True)\n",
    "    t=0\n",
    "    while  p>0.05 or q>0.05:\n",
    "        D_data=D_data.diff().dropna()\n",
    "        D_data.columns=[u'NAME']\n",
    "        D_data.dropna(inplace=True)\n",
    "        p=adfuller(D_data[u'NAME'],1)[1]\n",
    "        q=float(acorr_ljungbox(D_data,lags=1)[1]) \n",
    "        t=t+1            \n",
    "    return p,q,t\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "def mkdir(path): \n",
    "    folder = os.path.exists(path) \n",
    "    if not folder:                   #判?是否存在文件?如果不存在??建?文件?\n",
    "        os.makedirs(path)            #makedirs ?建文件?如果路?不存在??建??路?\n",
    "        print (\"創建新文件夾:%s\"%path)\n",
    "    else:\n",
    "        for info in os.listdir(path):\n",
    "            domain=os.path.abspath(path)  #?取文件?的路?\n",
    "            info=os.path.join(domain,info) \n",
    "            os.remove(info)\n",
    "            \n",
    "f=os.listdir('D:\\\\SPI')            \n",
    "for i1 in range(len(f)):   \n",
    "    file1 = \"D:\\\\SPI\\\\%s\\\\Real\"%f[i1]\n",
    "    mkdir(file1)\n",
    "    file2 = \"D:\\\\SPI\\\\%s\\\\Caculate\"%f[i1]\n",
    "    mkdir(file2)\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "batch=30\n",
    "N=30\n",
    "f=os.listdir('D:\\\\SPI')\n",
    "while 1==1:\n",
    "    for i in range(len(f)):\n",
    "        if not os.listdir('D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i]):\n",
    "            print('NO File to Do')\n",
    "            continue\n",
    "        else:\n",
    "            for info1 in os.listdir(r'D:\\\\SPI\\\\%s\\\\Model'%f[i]):       \n",
    "                a=info1.split('.')[0]        \n",
    "                for info2 in os.listdir(r'D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i]):    \n",
    "                    b=info2.split('_')[0]            \n",
    "                    if a==b:                \n",
    "                        c=a\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "            if os.path.exists('D:\\\\SPI\\\\%s\\\\Model\\\\%s.xlsx'%(f[i],c)):\n",
    "                path=pd.read_excel('D:\\\\SPI\\\\%s\\\\Model\\\\%s.xlsx'%(f[i],c))\n",
    "            elif os.path.exists('D:\\\\SPI\\\\%s\\\\Model\\\\%s.xls'%(f[i],c)):\n",
    "                path=pd.read_excel('D:\\\\SPI\\\\%s\\\\Model\\\\%s.xls'%(f[i],c))\n",
    "            elif os.path.exists('D:\\\\SPI\\\\%s\\\\Model\\\\%s.csv'%(f[i],c)):\n",
    "                path=pd.read_excel('D:\\\\SPI\\\\%s\\\\Model\\\\%s.csv'%(f[i],c))\n",
    "            pad=path.PAD\n",
    "            upA=path.upA    \n",
    "            downA=path.downA   \n",
    "            upH=path.upH\n",
    "            downH=path.downH   \n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------------------        \n",
    "        if not os.listdir('D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i]) or len([name for name in os.listdir(r'D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i])])<batch:\n",
    "            continue   #當文件個數小于batch時，跳?到下一?文件?\n",
    "        else:   \n",
    "            file1 = \"D:\\\\SPI\\\\%s\\\\Real\"%f[i]        \n",
    "            file2 = \"D:\\\\SPI\\\\%s\\\\Caculate\"%f[i]     \n",
    "            domain=os.path.abspath(r'D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i])  #?取文件?的路?\n",
    "            for info in os.listdir(r'D:\\\\SPI\\\\%s\\\\SPIDATA'%f[i]):\n",
    "                info=os.path.join(domain,info)    #?路?与文件名?合起?就是每?文件的完整路?\n",
    "                infoo=open(info,'r')    #?取文件?容 \n",
    "                d=infoo.readlines()\n",
    "                for j in range(len(pad)):  \n",
    "                    DT=[]\n",
    "                    PAD=[]\n",
    "                    HIGHT=[]\n",
    "                    AREA=[]\n",
    "                    for ii in range(len(d)):\n",
    "                        if d[ii].split(',')[1]==pad[j]:\n",
    "                            dt=d[ii].split(',')[0]\n",
    "                            dt=datetime.datetime.strptime(dt,'%Y/%m/%d %H:%M:%S')\n",
    "                            DT.append(dt)\n",
    "                            PAD.append(d[ii].split(',')[1])                        \n",
    "                            area=int(d[ii].split(',')[2])\n",
    "                            hight=int(d[ii].split(',')[3].split('\\n')[0])            \n",
    "                            HIGHT.append(hight)                        \n",
    "                            AREA.append(area)\n",
    "                        else:\n",
    "                            continue\n",
    "                    A=[DT,PAD,AREA,HIGHT]\n",
    "                    db=pd.DataFrame(A,index=['DateTime','Pad','HIGHT','AREA'])\n",
    "                    db=db.T\n",
    "                    db=db.drop_duplicates()  #移除重複值\n",
    "                    db.sort_values(by='DateTime',ascending=True,inplace=True)  #按升序排序數據，並覆蓋掉原來的\n",
    "\n",
    "                    for s in range(len(db)):  # 面積標準化 & 清洗異常值                                    \n",
    "                        if (db.AREA[s]/np.mean(db.AREA)>2) or (db.AREA[s]/np.mean(db.AREA)<0.5):\n",
    "                            db.AREA[s]=np.mean(db.AREA)\n",
    "                            db.HIGHT[s]=np.mean(db.HIGHT)                   \n",
    "\n",
    "                    fileName1='%s.txt'%pad[j]    #把每一個pad點的高度和面積存到對應的文件夾中\n",
    "                    filePath1=file1+os.path.sep+fileName1\n",
    "                    db.to_csv(filePath1,sep=',',index=False,header=None,mode='a+')  #['DateTime','Pad','HIGHT','AREA']\n",
    "                infoo.close()  #關閉已打開的文件 \n",
    "                os.remove(info)\n",
    "#--------------------------------------------------------------------------------------------------------------------------                         \n",
    "            for jj in  range(len(pad)):    #讀取文件夾下所有點的數據計算CPK     \n",
    "                fileName2='%s.txt'%pad[jj]\n",
    "                filePath2=file1+os.path.sep+fileName2\n",
    "                with open(filePath2, 'r') as ff:\n",
    "                    d2=ff.readlines()\n",
    "                    DateTime=[]\n",
    "                    Pad=[]\n",
    "                    HIGHT=[]\n",
    "                    AREA=[]\n",
    "                    for ii in range(len(d2)):\n",
    "                        dt=d2[ii].split(',')[0]\n",
    "                        ddt=datetime.datetime.strptime(dt,'%Y-%m-%d %H:%M:%S')\n",
    "                        DateTime.append(ddt)            \n",
    "                        Pad.append(d2[ii].split(',')[1])\n",
    "                        hight=int(d2[ii].split(',')[2])\n",
    "                        area=int(d2[ii].split(',')[3])   #.split('\\n')[0]                               \n",
    "                        HIGHT.append(hight)\n",
    "                        AREA.append(area)\n",
    "                    dd=[DateTime,Pad,HIGHT,AREA]\n",
    "                    dd=pd.DataFrame(dd,index=['DateTime','Pad','HIGHT','AREA'])\n",
    "                    db=dd.T \n",
    "                    db=db.drop_duplicates()\n",
    "                    db.sort_values(by='DateTime',ascending=True,inplace=True)\n",
    "\n",
    "                    upspcH=list(np.zeros(len(pad)))\n",
    "                    downspcH=list(np.zeros(len(pad)))\n",
    "                    upspcA=list(np.zeros(len(pad)))\n",
    "                    downspcA=list(np.zeros(len(pad)))\n",
    "                    if len(db)<N*batch:   #前面30個batch內的數據根據現有的全部數據計算規格上下限             \n",
    "                        upspcH[jj]=np.mean(db.HIGHT)+upH[jj]*np.std(db.HIGHT)\n",
    "                        downspcH[jj]=np.mean(db.HIGHT)-downH[jj]*np.std(db.HIGHT)\n",
    "                        upspcA[jj]=np.mean(db.AREA)+upA[jj]*np.std(db.AREA)\n",
    "                        downspcA[jj]=np.mean(db.AREA)-downA[jj]*np.std(db.AREA)\n",
    "                    else:                 #預測部分使用前面3個batch內的數據算規格上下限\n",
    "                        upspcH[jj]=np.mean(db.HIGHT[0:N*batch])+upH[jj]*np.std(db.HIGHT[0:N*batch])\n",
    "                        downspcH[jj]=np.mean(db.HIGHT[0:N*batch])-downH[jj]*np.std(db.HIGHT[0:N*batch])\n",
    "                        upspcA[jj]=np.mean(db.AREA[0:N*batch])+upA[jj]*np.std(db.AREA[0:N*batch])\n",
    "                        downspcA[jj]=np.mean(db.AREA[0:N*batch])-downA[jj]*np.std(db.AREA[0:N*batch])  \n",
    "\n",
    "                    CPKH=[]\n",
    "                    CPKA=[] \n",
    "                    TIME=[]\n",
    "                    preAREA=[]\n",
    "                    preHIGHT=[]\n",
    "                    preTIME=[]\n",
    "                    numlen=int(len(db)/batch)                \n",
    "                    for k in range(numlen):    \n",
    "                        cpkH=min((upspcH[jj]-np.mean(db.HIGHT[k*batch:(batch-1+batch*k)]))/(3*np.std(db.HIGHT[k*batch:(batch-1+batch*k)])),\\\n",
    "                               (np.mean(db.HIGHT[k*batch:(batch-1+batch*k)])-downspcH[jj])/(3*np.std(db.HIGHT[k*batch:(batch-1+batch*k)])))\n",
    "                        cpkA=min((upspcA[jj]-np.mean(db.AREA[k*batch:(batch-1+batch*k)]))/(3*np.std(db.AREA[k*batch:(batch-1+batch*k)])),\\\n",
    "                               (np.mean(db.AREA[k*batch:(batch-1+batch*k)])-downspcA[jj])/(3*np.std(db.AREA[k*batch:(batch-1+batch*k)])))\n",
    "                        Time=db.DateTime[k*batch+batch-1]\n",
    "                        d11=datetime.datetime.timestamp(Time)\n",
    "                        dateArray=time.localtime(d11)\n",
    "                        otherStyleTime =time.strftime('%Y-%m-%d %H:%M:%S',dateArray)   #dateArray.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        CPKH.append(cpkH)\n",
    "                        CPKA.append(cpkA)  \n",
    "                        TIME.append(otherStyleTime)  \n",
    "                    tha=[TIME,CPKH,CPKA]\n",
    "                    THA=pd.DataFrame(tha,index=['DateTime','CPKH','CPKA'])\n",
    "                    THA=THA.T\n",
    "                    THA=THA.drop_duplicates()\n",
    "                    THA.sort_values(by='DateTime',inplace=True)\n",
    "\n",
    "                    fileName3='%s.txt'%pad[jj]\n",
    "                    filePath3=file2+os.path.sep+fileName3\n",
    "                    THA.to_csv(filePath3,sep=',',index=False,header=None)  #,mode='a+'\n",
    "    #----------------------------------------------------------------------------------------------------------------#                   \n",
    "                    with open(filePath3, 'r') as ff:\n",
    "                        d2=ff.readlines()                                       \n",
    "                        if len(d2)<N:\n",
    "                            continue   # print(\"數據量小於%s組，暫時達不到建模條件\"%N)        \n",
    "                        else:  \n",
    "                            if len(d2)>50:\n",
    "                                d2=d2[(len(d2)-50):len(d2)]\n",
    "                            else:\n",
    "                                d2=d2\n",
    "                            TIME=[]\n",
    "                            CPKH=[]\n",
    "                            CPKA=[]  \n",
    "                            for ii in range(len(d2)):\n",
    "                                dt=d2[ii].split(',')[0]\n",
    "                                ddt=datetime.datetime.strptime(dt,'%Y-%m-%d %H:%M:%S')\n",
    "                                TIME.append(ddt) \n",
    "                                cpkh=float(d2[ii].split(',')[1])\n",
    "                                cpka=float(d2[ii].split(',')[2])\n",
    "                                CPKH.append(cpkh)\n",
    "                                CPKA.append(cpka)\n",
    "                            tha=[TIME,CPKH,CPKA]\n",
    "                            THA1=pd.DataFrame(tha,index=['TIME','CPKH','CPKA'])\n",
    "                            THA1=THA1.T\n",
    "                            THA1=THA1.drop_duplicates()\n",
    "                            THA1.sort_values(by='TIME',ascending=True,inplace=True)\n",
    "\n",
    "                            dataA=list(THA1.CPKA)\n",
    "                            dataH=list(THA1.CPKH)\n",
    "                            dataA=pd.DataFrame(dataA,columns=['NAME'])\n",
    "                            dataA.dropna(inplace=True)                \n",
    "                            dataH=pd.DataFrame(dataH,columns=['NAME'])  \n",
    "                            dataH.dropna(inplace=True)                    \n",
    "\n",
    "                            pmax=3\n",
    "                            qmax=3 \n",
    "                            dA=diff_data(dataA)[2]\n",
    "                            dH=diff_data(dataH)[2]    \n",
    "                            bic_matrixA=[]\n",
    "                            for pA in range(pmax+1):\n",
    "                                temp=[]\n",
    "                                for qA in range(qmax+1):\n",
    "                                    try:\n",
    "                                        temp.append(ARIMA(dataA,(pA,dA,qA)).fit().bic) #start_params=(0,0,0)\n",
    "                                    except:\n",
    "                                        temp.append(None)\n",
    "                                bic_matrixA.append(temp)\n",
    "                            bic_matrixA=pd.DataFrame(bic_matrixA)\n",
    "                            pA,qA=bic_matrixA.stack().astype('float64').idxmin()\n",
    "                #             print(u'BIC最小的p值和q值為：,%s,%s'%(pA,qA))\n",
    "                            modelA=ARIMA(dataA,(pA,dA,qA)).fit()\n",
    "\n",
    "                            bic_matrixH=[]\n",
    "                            for pH in range(pmax+1):\n",
    "                                temp=[]\n",
    "                                for qH in range(qmax+1):\n",
    "                                    try:\n",
    "                                        temp.append(ARIMA(dataH,(pH,dH,qH)).fit().bic)  #start_params=(0,0,0)\n",
    "                                    except:\n",
    "                                        temp.append(None)\n",
    "                                bic_matrixH.append(temp)\n",
    "                            bic_matrixH=pd.DataFrame(bic_matrixH)\n",
    "                            pH,qH=bic_matrixH.stack().astype('float64').idxmin()\n",
    "                #             print(u'BIC最小的p值和q值為：,%s,%s'%(pH,qH))\n",
    "                            modelH=ARIMA(dataH,(pH,dH,qH)).fit()\n",
    "\n",
    "                            preA=modelA.forecast(1)   #預測未來1組，返回預測結果，標準差，置信區間        \n",
    "                            preA=preA[0][0]\n",
    "                            preH=modelH.forecast(1)   #預測未來1組，返回預測結果，標準差，置信區間        \n",
    "                            preH=preH[0][0] \n",
    "\n",
    "                            d1=list(THA1.TIME)[-1]\n",
    "                            d2=list(THA1.TIME)[-2] \n",
    "                            d3=datetime.datetime.timestamp(d1)+datetime.datetime.timestamp(d1)-datetime.datetime.timestamp(d2)\n",
    "                            dateArray=time.localtime(d3)                #= datetime.datetime.utcfromtimestamp(d3)\n",
    "                            therStyleTime=time.strftime('%Y-%m-%d %H:%M:%S',dateArray)      \n",
    "                            preTIME.append(therStyleTime)\n",
    "\n",
    "                            preAREA.append(preA)                   \n",
    "                            preHIGHT.append(preH)   \n",
    "                            predictTHA=[preTIME,preAREA,preHIGHT]\n",
    "                            predictTHA=pd.DataFrame(predictTHA,index=['DateTime','CPKH','CPKA'])\n",
    "                            predictTHA=predictTHA.T\n",
    "                            predictTHA=predictTHA.drop_duplicates()\n",
    "                            predictTHA.sort_index(by='DateTime',inplace=True)\n",
    "\n",
    "                            fileName4='pre%s.txt'%pad[jj]\n",
    "                            filePath4=file2+os.path.sep+fileName4                    \n",
    "                            predictTHA.to_csv(filePath4,sep=',',index=False,header=None,mode='a+')  #,mode='a+'\n",
    "\n",
    "                            with open(filePath3, 'r') as f3:\n",
    "                                d3=f3.readlines()    \n",
    "                                HIGHT3=[]            \n",
    "                                AREA3=[]   \n",
    "                                DateTime3=[]\n",
    "                                for j3 in range(len(d3)):\n",
    "                                    dt3=d3[j3].split(',')[0]\n",
    "                                    ddt3=datetime.datetime.strptime(dt3,'%Y-%m-%d %H:%M:%S') \n",
    "                                    hight3=float(d3[j3].split(',')[1])\n",
    "                                    area3=float(d3[j3].split(',')[2].split('\\n')[0])   \n",
    "                                    DateTime3.append(ddt3)\n",
    "                                    HIGHT3.append(hight3)\n",
    "                                    AREA3.append(area3)    \n",
    "                              \n",
    "                            with open(filePath4, 'r') as f4:\n",
    "                                d4=f4.readlines()\n",
    "                                HIGHT4=[]            \n",
    "                                AREA4=[]   \n",
    "                                DateTime4=[]                                    \n",
    "                                for j4 in range(len(d4)):\n",
    "                                    dt4=d4[j4].split(',')[0]\n",
    "                                    ddt4=datetime.datetime.strptime(dt4,'%Y-%m-%d %H:%M:%S')  \n",
    "                                    hight4=float(d4[j4].split(',')[1])\n",
    "                                    area4=float(d4[j4].split(',')[2].split('\\n')[0])   \n",
    "                                    DateTime4.append(ddt4)\n",
    "                                    HIGHT4.append(hight4)\n",
    "                                    AREA4.append(area4)                  \n",
    "\n",
    "                            if len(d3)>len(d4) and len(d4)>1:\n",
    "                                for iii in range(len(d4)-1):\n",
    "                                    DateTime4[-iii-2]=DateTime3[-iii-1]\n",
    "                            elif len(d4)>len(d3) and len(d4)>1:\n",
    "                                 for iiii in range(len(d3)):\n",
    "                                    DateTime4[-iiii-2]=DateTime3[-iiii-1]\n",
    "\n",
    "                            dd4=[DateTime4,HIGHT4,AREA4]\n",
    "                            dd4=pd.DataFrame(dd4,index=['DateTime','HIGHT','AREA'])\n",
    "                            db4=dd4.T                                  \n",
    "                            db4.sort_values(by='DateTime',ascending=True,inplace=True)\n",
    "                            fileName5='predict_%s.txt'%pad[jj]\n",
    "                            filePath5=file2+os.path.sep+fileName5                    \n",
    "                            db4.to_csv(filePath5,sep=',',index=False,header=None)   \n",
    "                                              \n",
    "os.system(\"pause\")                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
